<title>always-on ar</title>
<h1>Future predictions: always-on AR</h1>
<i>(2020-06-03)</i>
<p>&emsp;
I think we'll end up having always-on AR (both vision and hearing).
Vision AR will take a form similar to Google Glass, and hearing will be fancier Airpods.
Both of these already exist, they just need to get better before people start always wearing them.
</p>
<p>&emsp;
The reason people will choose to wear always-on AR is pretty simple: convenience.
If you have always-on AR, you never have to worry about keeping your phone in your pocket,
or keeping files synced when you switch over to a computer,
or putting your earbuds in and out and back in again throughout the day.
</p>
<p>&emsp;
One (I'd argue the main) inconvenience with always-on hearing AR is that it's harder to hear the outside world.
(A similar issue doesn't apply to <i>vision</i> AR because the glasses are transparent.)
The way to solve that would be for earbuds to act like hearing aids: use a microphone to pick up the sounds outside,
and relay them into your ear.
Right now, we don't do that because it's simpler to just take off your earbuds instead,
but as computing takes up more and more of our lives, this'll make less and less sense.
We also don't do this because adding a really good mic in order to do this would either cost too much
or be technologically impossible.
But tech advances pretty quickly, so I don't see this as an issue.
</p>
<p>&emsp;
Two other minor inconveniences with AR are looking dumb and battery life.
Looking dumb will be dealt with over time by culture.
Some cool guy will start wearing the AR glasses, and then suddenly it's not thought of as stupid anymore.
Fashion adapts to practicality, not the other way around.
(Usually. I'm looking at you, wedding dresses.)
As for battery life, the solution is pretty obvious: make better batteries.
Technology gets better and batteries improve, so this one will be resolved soon enough.
</p>
<p>&emsp;
How will this AR be controlled?
In a word: everything.
I envision them having hand gesture sensors, voice input, eye motion sensors, etc.
The details are left up to user interface nerds, but a huge range of motions will probably be used to control it,
and it'll probably feel much more fluid and human than our current input methods because of this.
</p>
<p>&emsp;
The vision part of the AR will probably help with the naturalness as well.
We're getting better at simulating 3D objects in a picture (see: Snapchat filters, Minecraft Earth, etc.),
so much of the input will probably be able to look like parts of the world, rather than a HUD over your face.
When 2D interfaces are needed, they can be shown on 2D surfaces in the world.
</p>
<p>&emsp;
As for the hearing part, I'd imagine it would consist of the computer talking sometimes (fancy Alexa),
music, a bunch of small sound effects, voice calls,
and the real-world sound (but maybe edited with the relevant parts made louder and the irrelevant parts made quieter).
</p>
